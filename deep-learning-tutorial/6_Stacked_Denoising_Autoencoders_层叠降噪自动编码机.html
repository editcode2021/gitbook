
<!DOCTYPE HTML>
<html lang="" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>6.层叠降噪自动编码机 · GitBook</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.3">
        
        
        
    
    <link rel="stylesheet" href="gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="7_Restricted_Boltzmann_Machine_受限波尔兹曼机.html" />
    
    
    <link rel="prev" href="5_Denoising_Autoencoders_降噪自动编码.html" />
    

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="Type to search" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="./">
            
                <a href="./">
            
                    
                    简介
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="1_Getting_Started_入门.html">
            
                <a href="1_Getting_Started_入门.html">
            
                    
                    1.入门
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3" data-path="2_Classifying_MNIST_using_LR_逻辑回归进行MNIST分类.html">
            
                <a href="2_Classifying_MNIST_using_LR_逻辑回归进行MNIST分类.html">
            
                    
                    2.逻辑回归进行MNIST分类
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4" data-path="3_Multilayer_Perceptron_多层感知机.html">
            
                <a href="3_Multilayer_Perceptron_多层感知机.html">
            
                    
                    3.多层感知机
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5" data-path="4_Convoltional_Neural_Networks_LeNet_卷积神经网络.html">
            
                <a href="4_Convoltional_Neural_Networks_LeNet_卷积神经网络.html">
            
                    
                    4.卷积神经网络
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6" data-path="5_Denoising_Autoencoders_降噪自动编码.html">
            
                <a href="5_Denoising_Autoencoders_降噪自动编码.html">
            
                    
                    5.降噪自动编码
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="1.7" data-path="6_Stacked_Denoising_Autoencoders_层叠降噪自动编码机.html">
            
                <a href="6_Stacked_Denoising_Autoencoders_层叠降噪自动编码机.html">
            
                    
                    6.层叠降噪自动编码机
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.8" data-path="7_Restricted_Boltzmann_Machine_受限波尔兹曼机.html">
            
                <a href="7_Restricted_Boltzmann_Machine_受限波尔兹曼机.html">
            
                    
                    7.受限波尔兹曼机
            
                </a>
            

            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            Published with GitBook
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href="." >6.层叠降噪自动编码机</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h1 id="&#x5C42;&#x53E0;&#x964D;&#x566A;&#x81EA;&#x52A8;&#x7F16;&#x7801;&#x673A;&#xFF08;stacked-denoising-autoencoders-sda&#xFF09;">&#x5C42;&#x53E0;&#x964D;&#x566A;&#x81EA;&#x52A8;&#x7F16;&#x7801;&#x673A;&#xFF08;Stacked Denoising Autoencoders (SdA)&#xFF09;</h1>
<p>&#x5728;&#x8FD9;&#x4E00;&#x8282;&#xFF0C;&#x6211;&#x4EEC;&#x5047;&#x8BBE;&#x8BFB;&#x8005;&#x5DF2;&#x7ECF;&#x4E86;&#x89E3;&#x4E86;<a href="https://github.com/Syndrome777/DeepLearningTutorial/blob/master/2_Classifying_MNIST_using_LR_&#x903B;&#x8F91;&#x56DE;&#x5F52;&#x8FDB;&#x884C;MNIST&#x5206;&#x7C7B;.md" target="_blank">&#x4F7F;&#x7528;&#x903B;&#x8F91;&#x56DE;&#x5F52;&#x8FDB;&#x884C;MNIST&#x5206;&#x7C7B;</a>&#x548C;<a href="https://github.com/Syndrome777/DeepLearningTutorial/blob/master/3_Multilayer_Perceptron_&#x591A;&#x5C42;&#x611F;&#x77E5;&#x673A;.md" target="_blank">&#x591A;&#x5C42;&#x611F;&#x77E5;&#x673A;</a>&#x3002;&#x5982;&#x679C;&#x4F60;&#x9700;&#x8981;&#x5728;GPU&#x4E0A;&#x8FDB;&#x884C;&#x8FD0;&#x7B97;&#xFF0C;&#x4F60;&#x8FD8;&#x9700;&#x8981;&#x4E86;&#x89E3;<a href="http://deeplearning.net/software/theano/tutorial/using_gpu.html" target="_blank">GPU</a>&#x3002;</p>
<p>&#x672C;&#x8282;&#x7684;&#x6240;&#x6709;&#x4EE3;&#x7801;&#x53EF;&#x4EE5;&#x5728;<a href="http://deeplearning.net/tutorial/code/SdA.py" target="_blank">&#x8FD9;&#x91CC;</a>&#x4E0B;&#x8F7D;&#x3002;</p>
<p>&#x5C42;&#x53E0;&#x964D;&#x566A;&#x81EA;&#x52A8;&#x7F16;&#x7801;&#x673A;&#xFF08;Stacked Denoising Autoencoder&#xFF0C;SdA&#xFF09;&#x662F;&#x5C42;&#x53E0;&#x81EA;&#x52A8;&#x7F16;&#x7801;&#x673A;&#xFF08;<a href="http://deeplearning.net/tutorial/references.html#bengio07" target="_blank">Bengio07</a>&#xFF09;&#x7684;&#x4E00;&#x4E2A;&#x6269;&#x5C55;&#xFF0C;&#x5728;<a href="http://deeplearning.net/tutorial/references.html#vincent08" target="_blank">Vincent08</a>&#x4E2D;&#x88AB;&#x4ECB;&#x7ECD;&#x3002;</p>
<p>&#x8FD9;&#x4E2A;&#x6559;&#x7A0B;&#x5EFA;&#x7ACB;&#x5728;&#x524D;&#x4E00;&#x4E2A;<a href="https://github.com/Syndrome777/DeepLearningTutorial/blob/master/5_Denoising_Autoencoders_&#x964D;&#x566A;&#x81EA;&#x52A8;&#x7F16;&#x7801;.md" target="_blank">&#x964D;&#x566A;&#x81EA;&#x52A8;&#x7F16;&#x7801;&#x673A;</a>&#x4E4B;&#x4E0A;&#x3002;&#x6211;&#x4EEC;&#x5EFA;&#x8BAE;&#xFF0C;&#x5BF9;&#x4E8E;&#x6CA1;&#x6709;&#x81EA;&#x52A8;&#x7F16;&#x7801;&#x673A;&#x7ECF;&#x9A8C;&#x7684;&#x4EBA;&#x5E94;&#x8BE5;&#x9605;&#x8BFB;&#x4E0A;&#x8FF0;&#x7AE0;&#x8282;&#x3002;</p>
<h3 id="&#x5C42;&#x53E0;&#x81EA;&#x52A8;&#x7F16;&#x7801;&#x673A;">&#x5C42;&#x53E0;&#x81EA;&#x52A8;&#x7F16;&#x7801;&#x673A;</h3>
<p>&#x964D;&#x566A;&#x81EA;&#x52A8;&#x7F16;&#x7801;&#x673A;&#x53EF;&#x4EE5;&#x88AB;&#x53E0;&#x52A0;&#x8D77;&#x6765;&#x5F62;&#x6210;&#x4E00;&#x4E2A;&#x6DF1;&#x5EA6;&#x7F51;&#x7EDC;&#xFF0C;&#x901A;&#x8FC7;&#x53CD;&#x9988;&#x524D;&#x4E00;&#x5C42;&#x7684;&#x964D;&#x566A;&#x81EA;&#x52A8;&#x7F16;&#x7801;&#x673A;&#x7684;&#x6F5C;&#x5728;&#x8868;&#x8FBE;&#xFF08;&#x8F93;&#x51FA;&#x7F16;&#x7801;&#xFF09;&#x4F5C;&#x4E3A;&#x5F53;&#x524D;&#x5C42;&#x7684;&#x8F93;&#x5165;&#x3002;&#x8FD9;&#x4E2A;&#x975E;&#x76D1;&#x7763;&#x7684;&#x9884;&#x5B66;&#x4E60;&#x7ED3;&#x6784;&#x4E00;&#x6B21;&#x53EA;&#x80FD;&#x5B66;&#x4E60;&#x4E00;&#x4E2A;&#x5C42;&#x3002;&#x6BCF;&#x4E00;&#x5C42;&#x90FD;&#x88AB;&#x4F5C;&#x4E3A;&#x4E00;&#x4E2A;&#x964D;&#x566A;&#x81EA;&#x52A8;&#x7F16;&#x7801;&#x673A;&#x4EE5;&#x6700;&#x5C0F;&#x5316;&#x91CD;&#x6784;&#x8BEF;&#x5DEE;&#x6765;&#x8FDB;&#x884C;&#x8BAD;&#x7EC3;&#x3002;&#x5F53;&#x524D;k&#x4E2A;&#x5C42;&#x88AB;&#x8BAD;&#x7EC3;&#x5B8C;&#x4E86;&#xFF0C;&#x6211;&#x4EEC;&#x53EF;&#x4EE5;&#x8FDB;&#x884C;k+1&#x5C42;&#x7684;&#x8BAD;&#x7EC3;&#xFF0C;&#x56E0;&#x6B64;&#x6B64;&#x65F6;&#x6211;&#x4EEC;&#x624D;&#x53EF;&#x4EE5;&#x8BA1;&#x7B97;&#x524D;&#x4E00;&#x5C42;&#x7684;&#x7F16;&#x7801;&#x548C;&#x6F5C;&#x5728;&#x8868;&#x8FBE;&#x3002;&#x5F53;&#x6240;&#x6709;&#x7684;&#x5C42;&#x90FD;&#x88AB;&#x8BAD;&#x7EC3;&#x4E86;&#xFF0C;&#x6574;&#x4E2A;&#x7F51;&#x7EDC;&#x8FDB;&#x884C;&#x7B2C;&#x4E8C;&#x9636;&#x6BB5;&#x8BAD;&#x7EC3;&#xFF0C;&#x79F0;&#x4E3A;&#x5FAE;&#x8C03;&#xFF08;fine-tuning&#xFF09;&#x3002;&#x8FD9;&#x91CC;&#xFF0C;&#x6211;&#x4EEC;&#x8003;&#x8651;&#x76D1;&#x7763;&#x5FAE;&#x8C03;&#xFF0C;&#x5F53;&#x6211;&#x4EEC;&#x9700;&#x8981;&#x6700;&#x5C0F;&#x5316;&#x4E00;&#x4E2A;&#x76D1;&#x7763;&#x4EFB;&#x52A1;&#x7684;&#x9884;&#x6D4B;&#x8BEF;&#x5DEE;&#x5427;&#x3002;&#x4E3A;&#x6B64;&#x6211;&#x4EEC;&#x73B0;&#x5728;&#x7F51;&#x7EDC;&#x7684;&#x9876;&#x7AEF;&#x6DFB;&#x52A0;&#x4E00;&#x4E2A;&#x903B;&#x8F91;&#x56DE;&#x5F52;&#x5C42;&#xFF08;&#x4F7F;&#x8F93;&#x51FA;&#x5C42;&#x7684;&#x7F16;&#x7801;&#x66F4;&#x52A0;&#x7CBE;&#x786E;&#xFF09;&#x3002;&#x7136;&#x540E;&#x6211;&#x4EEC;&#x50CF;&#x8BAD;&#x7EC3;&#x591A;&#x5C42;&#x611F;&#x77E5;&#x5668;&#x4E00;&#x6837;&#x8BAD;&#x7EC3;&#x6574;&#x4E2A;&#x7F51;&#x7EDC;&#x3002;&#x8FD9;&#x91CC;&#xFF0C;&#x6211;&#x4EEC;&#x8003;&#x8651;&#x6BCF;&#x4E2A;&#x81EA;&#x52A8;&#x7F16;&#x7801;&#x7684;&#x673A;&#x7684;&#x7F16;&#x7801;&#x6A21;&#x5757;&#x3002;&#x8FD9;&#x4E2A;&#x9636;&#x6BB5;&#x662F;&#x6709;&#x76D1;&#x7763;&#x7684;&#xFF0C;&#x56E0;&#x4E3A;&#x6211;&#x4EEC;&#x5728;&#x8BAD;&#x7EC3;&#x7684;&#x65F6;&#x5019;&#x4F7F;&#x7528;&#x4E86;&#x76EE;&#x6807;&#x7C7B;&#x522B;&#xFF08;&#x66F4;&#x591A;&#x7EC6;&#x8282;&#x8BF7;&#x770B;<a href="https://github.com/Syndrome777/DeepLearningTutorial/blob/master/3_Multilayer_Perceptron_&#x591A;&#x5C42;&#x611F;&#x77E5;&#x673A;.md" target="_blank">&#x591A;&#x5C42;&#x611F;&#x77E5;&#x673A;</a>&#xFF09;</p>
<p><img src="images/6_sda_1.png" alt="SdA"></p>
<p>&#x8FD9;&#x5728;Theano&#x91CC;&#x9762;&#xFF0C;&#x4F7F;&#x7528;&#x4E4B;&#x524D;&#x5B9A;&#x4E49;&#x7684;&#x964D;&#x566A;&#x81EA;&#x52A8;&#x7F16;&#x7801;&#x673A;&#xFF0C;&#x53EF;&#x4EE5;&#x8F7B;&#x6613;&#x7684;&#x88AB;&#x5B9E;&#x73B0;&#x3002;&#x6211;&#x4EEC;&#x53EF;&#x4EE5;&#x5C06;&#x5C42;&#x53E0;&#x964D;&#x566A;&#x81EA;&#x52A8;&#x7F16;&#x7801;&#x673A;&#x770B;&#x4F5C;&#x4E24;&#x90E8;&#x5206;&#xFF0C;&#x4E00;&#x4E2A;&#x662F;&#x81EA;&#x52A8;&#x7F16;&#x7801;&#x673A;&#x94FE;&#x8868;&#xFF0C;&#x53E6;&#x4E00;&#x4E2A;&#x662F;&#x4E00;&#x4E2A;&#x591A;&#x5C42;&#x611F;&#x77E5;&#x673A;&#x3002;&#x5728;&#x9884;&#x8BAD;&#x7EC3;&#x9636;&#x6BB5;&#xFF0C;&#x6211;&#x4EEC;&#x4F7F;&#x7528;&#x4E86;&#x7B2C;&#x4E00;&#x90E8;&#x5206;&#xFF0C;&#x4F8B;&#x5982;&#x6211;&#x4EEC;&#x5C06;&#x6A21;&#x578B;&#x770B;&#x4F5C;&#x4E00;&#x7CFB;&#x5217;&#x7684;&#x81EA;&#x52A8;&#x7F16;&#x7801;&#x673A;&#xFF0C;&#x7136;&#x540E;&#x5206;&#x522B;&#x8BAD;&#x7EC3;&#x6BCF;&#x4E00;&#x4E2A;&#x81EA;&#x52A8;&#x7F16;&#x7801;&#x673A;&#x3002;&#x5728;&#x7B2C;&#x4E8C;&#x9636;&#x6BB5;&#xFF0C;&#x6211;&#x4EEC;&#x4F7F;&#x7528;&#x7B2C;&#x4E8C;&#x90E8;&#x5206;&#x3002;&#x8FD9;&#x4E2A;&#x4E24;&#x4E2A;&#x90E8;&#x5206;&#x901A;&#x8FC7;&#x5206;&#x4EAB;&#x53C2;&#x6570;&#x6765;&#x5B9E;&#x73B0;&#x8FDE;&#x63A5;&#x3002;</p>
<pre><code class="lang-Python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">SdA</span><span class="hljs-params">(object)</span>:</span>
    <span class="hljs-string">&quot;&quot;&quot;Stacked denoising auto-encoder class (SdA)

    A stacked denoising autoencoder model is obtained by stacking several
    dAs. The hidden layer of the dA at layer `i` becomes the input of
    the dA at layer `i+1`. The first layer dA gets as input the input of
    the SdA, and the hidden layer of the last dA represents the output.
    Note that after pretraining, the SdA is dealt with as a normal MLP,
    the dAs are only used to initialize the weights.
    &quot;&quot;&quot;</span>

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(
        self,
        numpy_rng,
        theano_rng=None,
        n_ins=<span class="hljs-number">784</span>,
        hidden_layers_sizes=[<span class="hljs-number">500</span>, <span class="hljs-number">500</span>],
        n_outs=<span class="hljs-number">10</span>,
        corruption_levels=[<span class="hljs-number">0.1</span>, <span class="hljs-number">0.1</span>]
    )</span>:</span>
        <span class="hljs-string">&quot;&quot;&quot; This class is made to support a variable number of layers.

        :type numpy_rng: numpy.random.RandomState
        :param numpy_rng: numpy random number generator used to draw initial
                    weights

        :type theano_rng: theano.tensor.shared_randomstreams.RandomStreams
        :param theano_rng: Theano random generator; if None is given one is
                           generated based on a seed drawn from `rng`

        :type n_ins: int
        :param n_ins: dimension of the input to the sdA

        :type n_layers_sizes: list of ints
        :param n_layers_sizes: intermediate layers size, must contain
                               at least one value

        :type n_outs: int
        :param n_outs: dimension of the output of the network

        :type corruption_levels: list of float
        :param corruption_levels: amount of corruption to use for each
                                  layer
        &quot;&quot;&quot;</span>

        self.sigmoid_layers = []
        self.dA_layers = []
        self.params = []
        self.n_layers = len(hidden_layers_sizes)

        <span class="hljs-keyword">assert</span> self.n_layers &gt; <span class="hljs-number">0</span>

        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> theano_rng:
            theano_rng = RandomStreams(numpy_rng.randint(<span class="hljs-number">2</span> ** <span class="hljs-number">30</span>))
        <span class="hljs-comment"># allocate symbolic variables for the data</span>
        self.x = T.matrix(<span class="hljs-string">&apos;x&apos;</span>)  <span class="hljs-comment"># the data is presented as rasterized images</span>
        self.y = T.ivector(<span class="hljs-string">&apos;y&apos;</span>)  <span class="hljs-comment"># the labels are presented as 1D vector of</span>
                                 <span class="hljs-comment"># [int] labels</span>
</code></pre>
<p><code>self.sigmoid_layers</code>&#x5C06;&#x4F1A;&#x50A8;&#x5B58;&#x591A;&#x5C42;&#x611F;&#x77E5;&#x673A;&#x7684;sigmoid&#x5C42;&#xFF0C;<code>self.dA_layers</code>&#x5C06;&#x4F1A;&#x50A8;&#x5B58;&#x8FDE;&#x63A5;&#x591A;&#x5C42;&#x611F;&#x77E5;&#x673A;&#x5C42;&#x7684;&#x964D;&#x566A;&#x81EA;&#x52A8;&#x7F16;&#x7801;&#x673A;&#x3002;</p>
<p>&#x4E0B;&#x4E00;&#x6B65;&#xFF0C;&#x6211;&#x4EEC;&#x6784;&#x5EFA;<code>n_layers</code>&#x4E2A;sigmoid&#x5C42;&#xFF08;&#x6211;&#x4EEC;&#x4F7F;&#x7528;&#x5728;<a href="https://github.com/Syndrome777/DeepLearningTutorial/blob/master/3_Multilayer_Perceptron_&#x591A;&#x5C42;&#x611F;&#x77E5;&#x673A;.md" target="_blank">&#x591A;&#x5C42;&#x611F;&#x77E5;&#x673A;</a>&#x4E2D;&#x4ECB;&#x7ECD;&#x7684;<code>HiddenLayer</code>&#x7C7B;&#xFF0C;&#x552F;&#x4E00;&#x7684;&#x66F4;&#x6539;&#x662F;&#x5C06;&#x539F;&#x672C;&#x7684;&#x975E;&#x7EBF;&#x6027;&#x51FD;&#x6570;<code>tanh</code>&#x6362;&#x6210;&#x4E86;logistic&#x51FD;&#x6570;s=1/(1+exp(-x))&#xFF09;&#x548C;<code>n_layers</code>&#x4E2A;&#x964D;&#x566A;&#x81EA;&#x52A8;&#x7F16;&#x7801;&#x673A;&#xFF0C;&#x5F53;&#x7136;<code>n_layers</code>&#x5C31;&#x662F;&#x6211;&#x4EEC;&#x6A21;&#x578B;&#x7684;&#x6DF1;&#x5EA6;&#x3002;&#x6211;&#x4EEC;&#x8FDE;&#x63A5;sigmoid&#x51FD;&#x6570;&#xFF0C;&#x4F7F;&#x5F97;&#x4ED6;&#x4EEC;&#x5F62;&#x6210;&#x4E00;&#x4E2A;MLP&#xFF0C;&#x6784;&#x5EFA;&#x6BCF;&#x4E00;&#x4E2A;&#x81EA;&#x52A8;&#x7F16;&#x7801;&#x673A;&#x548C;&#x4ED6;&#x4EEC;&#x5BF9;&#x5E94;&#x7684;sigmoid&#x5C42;&#xFF0C;&#x53BB;&#x5171;&#x4EAB;&#x7F16;&#x7801;&#x90E8;&#x5206;&#x7684;&#x6743;&#x503C;&#x77E9;&#x9635;&#x548C;&#x504F;&#x6267;</p>
<pre><code class="lang-Python">        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> xrange(self.n_layers):
            <span class="hljs-comment"># construct the sigmoidal layer</span>

            <span class="hljs-comment"># the size of the input is either the number of hidden units of</span>
            <span class="hljs-comment"># the layer below or the input size if we are on the first layer</span>
            <span class="hljs-keyword">if</span> i == <span class="hljs-number">0</span>:
                input_size = n_ins
            <span class="hljs-keyword">else</span>:
                input_size = hidden_layers_sizes[i - <span class="hljs-number">1</span>]

            <span class="hljs-comment"># the input to this layer is either the activation of the hidden</span>
            <span class="hljs-comment"># layer below or the input of the SdA if you are on the first</span>
            <span class="hljs-comment"># layer</span>
            <span class="hljs-keyword">if</span> i == <span class="hljs-number">0</span>:
                layer_input = self.x
            <span class="hljs-keyword">else</span>:
                layer_input = self.sigmoid_layers[<span class="hljs-number">-1</span>].output

            sigmoid_layer = HiddenLayer(rng=numpy_rng,
                                        input=layer_input,
                                        n_in=input_size,
                                        n_out=hidden_layers_sizes[i],
                                        activation=T.nnet.sigmoid)
            <span class="hljs-comment"># add the layer to our list of layers</span>
            self.sigmoid_layers.append(sigmoid_layer)
            <span class="hljs-comment"># its arguably a philosophical question...</span>
            <span class="hljs-comment"># but we are going to only declare that the parameters of the</span>
            <span class="hljs-comment"># sigmoid_layers are parameters of the StackedDAA</span>
            <span class="hljs-comment"># the visible biases in the dA are parameters of those</span>
            <span class="hljs-comment"># dA, but not the SdA</span>
            self.params.extend(sigmoid_layer.params)

            <span class="hljs-comment"># Construct a denoising autoencoder that shared weights with this</span>
            <span class="hljs-comment"># layer</span>
            dA_layer = dA(numpy_rng=numpy_rng,
                          theano_rng=theano_rng,
                          input=layer_input,
                          n_visible=input_size,
                          n_hidden=hidden_layers_sizes[i],
                          W=sigmoid_layer.W,
                          bhid=sigmoid_layer.b)
            self.dA_layers.append(dA_layer)
</code></pre>
<p>&#x73B0;&#x5728;&#xFF0C;&#x6211;&#x4EEC;&#x9700;&#x8981;&#x5728;sigmoid&#x5C42;&#x7684;&#x4E0A;&#x65B9;&#x6DFB;&#x52A0;&#x903B;&#x8F91;&#x5C42;&#xFF0C;&#x6240;&#x4EE5;&#x6211;&#x4EEC;&#x5C06;&#x6709;&#x4E00;&#x4E2A;MLP&#x3002;&#x6211;&#x4EEC;&#x5C06;&#x4F7F;&#x7528;&#x5728;<a href="https://github.com/Syndrome777/DeepLearningTutorial/blob/master/2_Classifying_MNIST_using_LR_&#x903B;&#x8F91;&#x56DE;&#x5F52;&#x8FDB;&#x884C;MNIST&#x5206;&#x7C7B;.md" target="_blank">&#x4F7F;&#x7528;&#x903B;&#x8F91;&#x56DE;&#x5F52;&#x8FDB;MNIST&#x5206;&#x7C7B;</a>&#x7684;<code>LogisticRegression</code>&#x7C7B;&#x3002;</p>
<pre><code class="lang-Python">        <span class="hljs-comment"># We now need to add a logistic layer on top of the MLP</span>
        self.logLayer = LogisticRegression(
            input=self.sigmoid_layers[<span class="hljs-number">-1</span>].output,
            n_in=hidden_layers_sizes[<span class="hljs-number">-1</span>],
            n_out=n_outs
        )

        self.params.extend(self.logLayer.params)
        <span class="hljs-comment"># construct a function that implements one step of finetunining</span>

        <span class="hljs-comment"># compute the cost for second phase of training,</span>
        <span class="hljs-comment"># defined as the negative log likelihood</span>
        self.finetune_cost = self.logLayer.negative_log_likelihood(self.y)
        <span class="hljs-comment"># compute the gradients with respect to the model parameters</span>
        <span class="hljs-comment"># symbolic variable that points to the number of errors made on the</span>
        <span class="hljs-comment"># minibatch given by self.x and self.y</span>
        self.errors = self.logLayer.errors(self.y)
</code></pre>
<p>&#x8FD9;&#x4E2A;&#x7C7B;&#x4E5F;&#x63D0;&#x4F9B;&#x4E00;&#x4E2A;&#x65B9;&#x6CD5;&#x53BB;&#x4EA7;&#x751F;&#x4E0E;&#x4E0D;&#x540C;&#x5C42;&#x76F8;&#x5173;&#x7684;&#x964D;&#x566A;&#x81EA;&#x52A8;&#x7F16;&#x7801;&#x673A;&#x7684;&#x8BAD;&#x7EC3;&#x51FD;&#x6570;&#x3002;&#x5B83;&#x4EEC;&#x4EE5;list&#x7684;&#x5F62;&#x5F0F;&#x8FD4;&#x56DE;&#xFF0C;&#x7B2C;i&#x4E2A;&#x5143;&#x7D20;&#x5C31;&#x662F;&#x4E00;&#x4E2A;&#x5B9E;&#x73B0;&#x8BAD;&#x7EC3;&#x7B2C;i&#x5C42;&#x7684;<code>dA</code>&#x7684;&#x51FD;&#x6570;&#x3002;</p>
<pre><code class="lang-Python">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">pretraining_functions</span><span class="hljs-params">(self, train_set_x, batch_size)</span>:</span>
        <span class="hljs-string">&apos;&apos;&apos; Generates a list of functions, each of them implementing one
        step in trainnig the dA corresponding to the layer with same index.
        The function will require as input the minibatch index, and to train
        a dA you just need to iterate, calling the corresponding function on
        all minibatch indexes.

        :type train_set_x: theano.tensor.TensorType
        :param train_set_x: Shared variable that contains all datapoints used
                            for training the dA

        :type batch_size: int
        :param batch_size: size of a [mini]batch

        :type learning_rate: float
        :param learning_rate: learning rate used during training for any of
                              the dA layers
        &apos;&apos;&apos;</span>

        <span class="hljs-comment"># index to a [mini]batch</span>
        index = T.lscalar(<span class="hljs-string">&apos;index&apos;</span>)  <span class="hljs-comment"># index to a minibatch</span>
</code></pre>
<p>&#x4E3A;&#x4E86;&#x6709;&#x80FD;&#x529B;&#x5728;&#x8BAD;&#x7EC3;&#x65F6;&#xFF0C;&#x6539;&#x53D8;&#x5DEE;&#x9519;&#x7B49;&#x7EA7;&#x6216;&#x8005;&#x8BAD;&#x7EC3;&#x901F;&#x7387;&#x3002;&#x6211;&#x4EEC;&#x7528;&#x4E00;&#x4E2A;Theano&#x53D8;&#x91CF;&#x6765;&#x8054;&#x7CFB;&#x5B83;&#x4EEC;&#x3002;</p>
<pre><code class="lang-Python">        corruption_level = T.scalar(<span class="hljs-string">&apos;corruption&apos;</span>)  <span class="hljs-comment"># % of corruption to use</span>
        learning_rate = T.scalar(<span class="hljs-string">&apos;lr&apos;</span>)  <span class="hljs-comment"># learning rate to use</span>
        <span class="hljs-comment"># begining of a batch, given `index`</span>
        batch_begin = index * batch_size
        <span class="hljs-comment"># ending of a batch given `index`</span>
        batch_end = batch_begin + batch_size

        pretrain_fns = []
        <span class="hljs-keyword">for</span> dA <span class="hljs-keyword">in</span> self.dA_layers:
            <span class="hljs-comment"># get the cost and the updates list</span>
            cost, updates = dA.get_cost_updates(corruption_level,
                                                learning_rate)
            <span class="hljs-comment"># compile the theano function</span>
            fn = theano.function(
                inputs=[
                    index,
                    theano.Param(corruption_level, default=<span class="hljs-number">0.2</span>),
                    theano.Param(learning_rate, default=<span class="hljs-number">0.1</span>)
                ],
                outputs=cost,
                updates=updates,
                givens={
                    self.x: train_set_x[batch_begin: batch_end]
                }
            )
            <span class="hljs-comment"># append `fn` to the list of functions</span>
            pretrain_fns.append(fn)

        <span class="hljs-keyword">return</span> pretrain_fns
</code></pre>
<p>&#x73B0;&#x5728;&#x4EFB;&#x4F55;&#x4E00;&#x4E2A;<code>pretrain_fns[i]</code>&#x51FD;&#x6570;&#xFF0C;&#x53EF;&#x4EE5;&#x5C06;<code>index</code>&#xFF0C;<code>corruption</code>&#x2014;&#x2014;&#x5DEE;&#x9519;&#x7B49;&#x7EA7;&#xFF0C;<code>lr</code>&#x2014;&#x2014;&#x5B66;&#x4E60;&#x901F;&#x7387;&#x4F5C;&#x4E3A;&#x53C2;&#x6570;&#x3002;&#x6CE8;&#x610F;&#xFF0C;&#x8FD9;&#x4E9B;&#x53C2;&#x6570;&#x7684;&#x540D;&#x5B57;&#x662F;Theano&#x53D8;&#x91CF;&#x7684;&#x540D;&#x5B57;&#xFF0C;&#x800C;&#x4E0D;&#x662F;Python&#x53D8;&#x91CF;&#x7684;&#x540D;&#x5B57;&#xFF08;<code>learning_rate</code>&#x6216;&#x8005;<code>corruption_level</code>&#xFF09;&#x3002;&#x5728;&#x4F7F;&#x7528;Theano&#x65F6;&#xFF0C;&#x6CE8;&#x610F;&#x8FD9;&#x4E00;&#x70B9;&#x3002;</p>
<p>&#x4EE5;&#x76F8;&#x540C;&#x7684;&#x65B9;&#x5F0F;&#xFF08;fashion&#xFF09;&#xFF0C;&#x6211;&#x4EEC;&#x521B;&#x5EFA;&#x4E86;&#x4E00;&#x4E2A;&#x65B9;&#x6CD5;&#x7528;&#x4E8E;&#x5728;&#x5FAE;&#x8C03;&#xFF08;fine-tuning&#xFF09;&#x65F6;&#x9700;&#x8981;&#x7684;&#x6784;&#x5EFA;&#x51FD;&#x6570;&#xFF08;<code>train_model</code>&#xFF0C;<code>validate_model</code>&#xFF0C;<code>test_model</code>&#x51FD;&#x6570;&#xFF09;&#x3002;</p>
<pre><code class="lang-Python">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">build_finetune_functions</span><span class="hljs-params">(self, datasets, batch_size, learning_rate)</span>:</span>
        <span class="hljs-string">&apos;&apos;&apos;Generates a function `train` that implements one step of
        finetuning, a function `validate` that computes the error on
        a batch from the validation set, and a function `test` that
        computes the error on a batch from the testing set

        :type datasets: list of pairs of theano.tensor.TensorType
        :param datasets: It is a list that contain all the datasets;
                         the has to contain three pairs, `train`,
                         `valid`, `test` in this order, where each pair
                         is formed of two Theano variables, one for the
                         datapoints, the other for the labels

        :type batch_size: int
        :param batch_size: size of a minibatch

        :type learning_rate: float
        :param learning_rate: learning rate used during finetune stage
        &apos;&apos;&apos;</span>

        (train_set_x, train_set_y) = datasets[<span class="hljs-number">0</span>]
        (valid_set_x, valid_set_y) = datasets[<span class="hljs-number">1</span>]
        (test_set_x, test_set_y) = datasets[<span class="hljs-number">2</span>]

        <span class="hljs-comment"># compute number of minibatches for training, validation and testing</span>
        n_valid_batches = valid_set_x.get_value(borrow=<span class="hljs-keyword">True</span>).shape[<span class="hljs-number">0</span>]
        n_valid_batches /= batch_size
        n_test_batches = test_set_x.get_value(borrow=<span class="hljs-keyword">True</span>).shape[<span class="hljs-number">0</span>]
        n_test_batches /= batch_size

        index = T.lscalar(<span class="hljs-string">&apos;index&apos;</span>)  <span class="hljs-comment"># index to a [mini]batch</span>

        <span class="hljs-comment"># compute the gradients with respect to the model parameters</span>
        gparams = T.grad(self.finetune_cost, self.params)

        <span class="hljs-comment"># compute list of fine-tuning updates</span>
        updates = [
            (param, param - gparam * learning_rate)
            <span class="hljs-keyword">for</span> param, gparam <span class="hljs-keyword">in</span> zip(self.params, gparams)
        ]

        train_fn = theano.function(
            inputs=[index],
            outputs=self.finetune_cost,
            updates=updates,
            givens={
                self.x: train_set_x[
                    index * batch_size: (index + <span class="hljs-number">1</span>) * batch_size
                ],
                self.y: train_set_y[
                    index * batch_size: (index + <span class="hljs-number">1</span>) * batch_size
                ]
            },
            name=<span class="hljs-string">&apos;train&apos;</span>
        )

        test_score_i = theano.function(
            [index],
            self.errors,
            givens={
                self.x: test_set_x[
                    index * batch_size: (index + <span class="hljs-number">1</span>) * batch_size
                ],
                self.y: test_set_y[
                    index * batch_size: (index + <span class="hljs-number">1</span>) * batch_size
                ]
            },
            name=<span class="hljs-string">&apos;test&apos;</span>
        )

        valid_score_i = theano.function(
            [index],
            self.errors,
            givens={
                self.x: valid_set_x[
                    index * batch_size: (index + <span class="hljs-number">1</span>) * batch_size
                ],
                self.y: valid_set_y[
                    index * batch_size: (index + <span class="hljs-number">1</span>) * batch_size
                ]
            },
            name=<span class="hljs-string">&apos;valid&apos;</span>
        )

        <span class="hljs-comment"># Create a function that scans the entire validation set</span>
        <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">valid_score</span><span class="hljs-params">()</span>:</span>
            <span class="hljs-keyword">return</span> [valid_score_i(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> xrange(n_valid_batches)]

        <span class="hljs-comment"># Create a function that scans the entire test set</span>
        <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">test_score</span><span class="hljs-params">()</span>:</span>
            <span class="hljs-keyword">return</span> [test_score_i(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> xrange(n_test_batches)]

        <span class="hljs-keyword">return</span> train_fn, valid_score, test_score
</code></pre>
<p>&#x6CE8;&#x610F;&#xFF0C;&#x8FD9;&#x91CC;&#x8FD4;&#x56DE;&#x7684;<code>valid_score</code>&#x548C;<code>test_score</code>&#x5E76;&#x4E0D;&#x662F;Theano&#x51FD;&#x6570;&#xFF0C;&#x800C;&#x662F;Python&#x51FD;&#x6570;&#xFF0C;&#x5728;&#x6574;&#x4E2A;&#x9A8C;&#x8BC1;&#x96C6;&#x548C;&#x6D4B;&#x8BD5;&#x96C6;&#x5FAA;&#x73AF;&#xFF0C;&#x4EE5;&#x4EA7;&#x751F;&#x8FD9;&#x4E9B;&#x96C6;&#x5408;&#x7684;&#x635F;&#x5931;&#x6570;&#x7684;list&#x3002;</p>
<h3 id="&#x5C06;&#x5B83;&#x7EC4;&#x5408;&#x8D77;&#x6765;">&#x5C06;&#x5B83;&#x7EC4;&#x5408;&#x8D77;&#x6765;</h3>
<p>&#x4E0B;&#x9762;&#x7684;&#x51E0;&#x884C;&#x4EE3;&#x7801;&#x53BB;&#x6784;&#x5EFA;&#x5C42;&#x53E0;&#x81EA;&#x52A8;&#x7F16;&#x7801;&#x673A;&#xFF1A;</p>
<pre><code class="lang-Python">    numpy_rng = numpy.random.RandomState(<span class="hljs-number">89677</span>)
    <span class="hljs-keyword">print</span> <span class="hljs-string">&apos;... building the model&apos;</span>
    <span class="hljs-comment"># construct the stacked denoising autoencoder class</span>
    sda = SdA(
        numpy_rng=numpy_rng,
        n_ins=<span class="hljs-number">28</span> * <span class="hljs-number">28</span>,
        hidden_layers_sizes=[<span class="hljs-number">1000</span>, <span class="hljs-number">1000</span>, <span class="hljs-number">1000</span>],
        n_outs=<span class="hljs-number">10</span>
    )
</code></pre>
<p>&#x5728;&#x8BAD;&#x7EC3;&#x8FD9;&#x4E2A;&#x7F51;&#x7EDC;&#x65F6;&#xFF0C;&#x6709;&#x4E24;&#x4E2A;&#x9636;&#x6BB5;&#xFF0C;&#x4E00;&#x5C42;&#x662F;&#x9884;&#x8BAD;&#x7EC3;&#xFF0C;&#x4E4B;&#x540E;&#x662F;&#x5FAE;&#x8C03;&#x3002;</p>
<p>&#x5BF9;&#x4E8E;&#x9884;&#x8BAD;&#x7EC3;&#x9636;&#x6BB5;&#xFF0C;&#x6211;&#x4EEC;&#x5C06;&#x5FAA;&#x73AF;&#x7F51;&#x7EDC;&#x4E2D;&#x7684;&#x6240;&#x6709;&#x5C42;&#x3002;&#x5BF9;&#x4E8E;&#x6BCF;&#x4E00;&#x5C42;&#xFF0C;&#x6211;&#x4EEC;&#x5C06;&#x4F7F;&#x7528;&#x7F16;&#x8BD1;&#x7684;theano&#x51FD;&#x6570;&#x6765;&#x5B9E;&#x73B0;SGD(&#x968F;&#x673A;&#x68AF;&#x5EA6;&#x4E0B;&#x964D;)&#xFF0C;&#x4EE5;&#x5B9E;&#x73B0;&#x6743;&#x503C;&#x4F18;&#x5316;&#xFF0C;&#x6765;&#x89C1;&#x6548;&#x6BCF;&#x5C42;&#x7684;&#x91CD;&#x6784;&#x635F;&#x5931;&#x3002;&#x8FD9;&#x4E2A;&#x51FD;&#x6570;&#x5C06;&#x5728;&#x8BAD;&#x7EC3;&#x96C6;&#x4E2D;&#x88AB;&#x5E94;&#x7528;&#xFF0C;&#x5E76;&#x4E14;&#x662F;&#x4EE5;<code>pretraining_epochs</code>&#x4E2D;&#x7ED9;&#x51FA;&#x7684;&#x56FA;&#x5B9A;&#x6B21;&#x6570;&#x7684;&#x8FED;&#x4EE3;&#x3002;</p>
<pre><code class="lang-Python">    <span class="hljs-comment">#########################</span>
    <span class="hljs-comment"># PRETRAINING THE MODEL #</span>
    <span class="hljs-comment">#########################</span>
    <span class="hljs-keyword">print</span> <span class="hljs-string">&apos;... getting the pretraining functions&apos;</span>
    pretraining_fns = sda.pretraining_functions(train_set_x=train_set_x,
                                                batch_size=batch_size)

    <span class="hljs-keyword">print</span> <span class="hljs-string">&apos;... pre-training the model&apos;</span>
    start_time = time.clock()
    <span class="hljs-comment">## Pre-train layer-wise</span>
    corruption_levels = [<span class="hljs-number">.1</span>, <span class="hljs-number">.2</span>, <span class="hljs-number">.3</span>]
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> xrange(sda.n_layers):
        <span class="hljs-comment"># go through pretraining epochs</span>
        <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> xrange(pretraining_epochs):
            <span class="hljs-comment"># go through the training set</span>
            c = []
            <span class="hljs-keyword">for</span> batch_index <span class="hljs-keyword">in</span> xrange(n_train_batches):
                c.append(pretraining_fns[i](index=batch_index,
                         corruption=corruption_levels[i],
                         lr=pretrain_lr))
            <span class="hljs-keyword">print</span> <span class="hljs-string">&apos;Pre-training layer %i, epoch %d, cost &apos;</span> % (i, epoch),
            <span class="hljs-keyword">print</span> numpy.mean(c)

    end_time = time.clock()

    <span class="hljs-keyword">print</span> &gt;&gt; sys.stderr, (<span class="hljs-string">&apos;The pretraining code for file &apos;</span> +
                          os.path.split(__file__)[<span class="hljs-number">1</span>] +
                          <span class="hljs-string">&apos; ran for %.2fm&apos;</span> % ((end_time - start_time) / <span class="hljs-number">60.</span>))
</code></pre>
<p>&#x8FD9;&#x4E2A;&#x5FAE;&#x8C03;&#xFF08;fine-tuning&#xFF09;&#x5FAA;&#x73AF;&#x548C;<a href="https://github.com/Syndrome777/DeepLearningTutorial/blob/master/3_Multilayer_Perceptron_&#x591A;&#x5C42;&#x611F;&#x77E5;&#x673A;.md" target="_blank">&#x591A;&#x5C42;&#x611F;&#x77E5;&#x673A;</a>&#x4E2D;&#x7684;&#x975E;&#x5E38;&#x7C7B;&#x4F3C;&#xFF0C;&#x552F;&#x4E00;&#x7684;&#x4E0D;&#x540C;&#x662F;&#x6211;&#x4EEC;&#x5C06;&#x4F7F;&#x7528;&#x5728;<code>build_funetune_functions</code>&#x4E2D;&#x7ED9;&#x5B9A;&#x7684;&#x65B0;&#x51FD;&#x6570;&#x3002;</p>
<h3 id="&#x8FD0;&#x884C;&#x8FD9;&#x4E2A;&#x4EE3;&#x7801;">&#x8FD0;&#x884C;&#x8FD9;&#x4E2A;&#x4EE3;&#x7801;</h3>
<p>&#x9ED8;&#x8BA4;&#x60C5;&#x51B5;&#x4E0B;&#xFF0C;&#x8FD9;&#x4E2A;&#x4EE3;&#x7801;&#x4EE5;&#x5757;&#x6570;&#x76EE;&#x4E3A;1&#xFF0C;&#x6BCF;&#x4E00;&#x5C42;&#x5FAA;&#x73AF;15&#x6B21;&#x6765;&#x8FDB;&#x884C;&#x9884;&#x8BAD;&#x7EC3;&#x9884;&#x8BAD;&#x7EC3;&#x3002;&#x9519;&#x5DEE;&#x7B49;&#x7EA7;&#xFF08;corruption level&#xFF09;&#x5728;&#x7B2C;&#x4E00;&#x5C42;&#x88AB;&#x8BBE;&#x4E3A;0.1&#xFF0C;&#x7B2C;&#x4E8C;&#x5C42;&#x88AB;&#x8BBE;&#x4E3A;0.2&#xFF0C;&#x7B2C;&#x4E09;&#x5C42;&#x88AB;&#x8BBE;&#x4E3A;0.3&#x3002;&#x9884;&#x8BAD;&#x7EC3;&#x7684;&#x5B66;&#x4E60;&#x901F;&#x7387;&#x4E3A;0.001&#xFF0C;&#x5FAE;&#x8C03;&#x5B66;&#x4E60;&#x901F;&#x7387;&#x4E3A;0.1&#x3002;&#x9884;&#x8BAD;&#x7EC3;&#x82B1;&#x4E86;585.01&#x5206;&#x949F;&#xFF0C;&#x5E73;&#x5747;&#x6BCF;&#x5C42;13&#x5206;&#x949F;&#x3002;&#x5FAE;&#x8C03;&#x5728;36&#x6B21;&#x8FED;&#x4EE3;&#xFF0C;444.2&#x5206;&#x949F;&#x540E;&#x5B8C;&#x6210;&#x3002;&#x5E73;&#x5747;&#x6BCF;&#x5C42;&#x8FED;&#x4EE3;12.34&#x5206;&#x949F;&#x3002;&#x6700;&#x540E;&#x7684;&#x9A8C;&#x8BC1;&#x5F97;&#x5206;&#x4E3A;1.39%&#xFF0C;&#x6D4B;&#x8BD5;&#x5F97;&#x5206;&#x4E3A;1.3%&#x3002;&#x6240;&#x6709;&#x7684;&#x7ED3;&#x679C;&#x90FD;&#x662F;&#x5728;Intel Xeon E5430 @ 2.66GHz CPU&#xFF0C;GotoBLAS&#x4E0B;&#x5F97;&#x51FA;&#x3002;</p>
<h3 id="&#x6280;&#x5DE7;">&#x6280;&#x5DE7;</h3>
<p>&#x8FD9;&#x91CC;&#x6709;&#x4E00;&#x4E2A;&#x65B9;&#x6CD5;&#x53BB;&#x63D0;&#x9AD8;&#x4EE3;&#x7801;&#x7684;&#x8FD0;&#x884C;&#x901F;&#x5EA6;&#xFF08;&#x5047;&#x5B9A;&#x4F60;&#x6709;&#x8DB3;&#x591F;&#x7684;&#x53EF;&#x7528;&#x5185;&#x5B58;&#xFF09;&#xFF0C;&#x662F;&#x53BB;&#x8BA1;&#x7B97;&#x8FD9;&#x4E2A;&#x7F51;&#x7EDC;&#xFF08;&#x76F4;&#x5230;&#x7B2C;k-1&#x5C42;&#x65F6;&#xFF09;&#x5982;&#x4F55;&#x8F6C;&#x6362;&#x4F60;&#x7684;&#x6570;&#x636E;&#x3002;&#x6362;&#x53E5;&#x8BDD;&#x8BF4;&#xFF0C;&#x4F60;&#x901A;&#x8FC7;&#x8BAD;&#x7EC3;&#x4F60;&#x7684;&#x7B2C;&#x4E00;&#x4E2A;dA&#x5C42;&#x6765;&#x5F00;&#x59CB;&#x3002;&#x4E00;&#x65E6;&#x5B83;&#x88AB;&#x8BAD;&#x7EC3;&#xFF0C;&#x4F60;&#x5C31;&#x53EF;&#x4EE5;&#x4E3A;&#x6BCF;&#x4E00;&#x4E2A;&#x6570;&#x636E;&#x8282;&#x70B9;&#x8BA1;&#x7B97;&#x9690;&#x5355;&#x5143;&#x7684;&#x503C;&#x7136;&#x540E;&#x5C06;&#x5B83;&#x4EEC;&#x50A8;&#x5B58;&#x4E3A;&#x4E00;&#x4E2A;&#x65B0;&#x7684;&#x6570;&#x636E;&#x96C6;&#xFF0C;&#x4EE5;&#x4FBF;&#x4F60;&#x5728;&#x7B2C;2&#x5C42;&#x4E2D;&#x8BAD;&#x7EC3;dA&#x3002;&#x4E00;&#x65E6;&#x4F60;&#x8BAD;&#x7EC3;&#x5B8C;&#x7B2C;2&#x5C42;&#x7684;dA&#xFF0C;&#x4F60;&#x4EE5;&#x76F8;&#x540C;&#x7684;&#x65B9;&#x5F0F;&#x8BA1;&#x7B97;&#x7B2C;&#x4E09;&#x5C42;&#x7684;&#x6570;&#x636E;&#x3002;&#x73B0;&#x5728;&#x4F60;&#x53EF;&#x4EE5;&#x660E;&#x767D;&#xFF0C;&#x5728;&#x8FD9;&#x4E2A;&#x65F6;&#x5019;&#xFF0C;&#x8FD9;&#x4E2A;dAs&#x88AB;&#x5206;&#x5F00;&#x8BAD;&#x7EC3;&#x4E86;&#xFF0C;&#x5B83;&#x4EEC;&#x4EC5;&#x4EC5;&#x63D0;&#x4F9B;&#xFF08;&#x4E00;&#x5BF9;&#x4E00;&#x7684;&#xFF09;&#x5BF9;&#x8F93;&#x5165;&#x7684;&#x975E;&#x7EBF;&#x6027;&#x8F6C;&#x6362;&#x3002;&#x4E00;&#x65E6;&#x6240;&#x6709;&#x7684;dAs&#x88AB;&#x8BAD;&#x7EC3;&#xFF0C;&#x4F60;&#x5C31;&#x53EF;&#x4EE5;&#x5F00;&#x59CB;&#x5FAE;&#x8C03;&#x6574;&#x4E2A;&#x6A21;&#x578B;&#x4E86;&#x3002;</p>

                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="5_Denoising_Autoencoders_降噪自动编码.html" class="navigation navigation-prev " aria-label="Previous page: 5.降噪自动编码">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="7_Restricted_Boltzmann_Machine_受限波尔兹曼机.html" class="navigation navigation-next " aria-label="Next page: 7.受限波尔兹曼机">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"6.层叠降噪自动编码机","level":"1.7","depth":1,"next":{"title":"7.受限波尔兹曼机","level":"1.8","depth":1,"path":"7_Restricted_Boltzmann_Machine_受限波尔兹曼机.md","ref":"7_Restricted_Boltzmann_Machine_受限波尔兹曼机.md","articles":[]},"previous":{"title":"5.降噪自动编码","level":"1.6","depth":1,"path":"5_Denoising_Autoencoders_降噪自动编码.md","ref":"5_Denoising_Autoencoders_降噪自动编码.md","articles":[]},"dir":"ltr"},"config":{"gitbook":"*","theme":"default","variables":{},"plugins":[],"pluginsConfig":{"highlight":{},"search":{},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"fontsettings":{"theme":"white","family":"sans","size":2},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"}},"file":{"path":"6_Stacked_Denoising_Autoencoders_层叠降噪自动编码机.md","mtime":"2017-07-12T16:21:46.000Z","type":"markdown"},"gitbook":{"version":"3.2.3","time":"2021-05-10T15:44:26.709Z"},"basePath":".","book":{"language":""}});
        });
    </script>
</div>

        
    <script src="gitbook/gitbook.js"></script>
    <script src="gitbook/theme.js"></script>
    
        
        <script src="gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-sharing/buttons.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

