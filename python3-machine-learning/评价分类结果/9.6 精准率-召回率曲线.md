# 9.6 精准率-召回率曲线

### 召回率曲线


```python
import numpy as np 
from sklearn import datasets

digits = datasets.load_digits()

X = digits.data
y = digits.target.copy()

# 手动将手写数据集变成及其偏斜的数据。不是9的y=0，是9的y=1
y[digits.target==9] = 1
y[digits.target!=9] = 0
```


```python
from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=666)
```


```python
from sklearn.linear_model import LogisticRegression

log_reg = LogisticRegression()
log_reg.fit(X_train,y_train)
decision_scores = log_reg.decision_function(X_test)
```


```python
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score

precisions = []
recalls = []
thresholds = np.arange(np.min(decision_scores), np.max(decision_scores))

for threshold in thresholds:
    y_predict = np.array(decision_scores >= threshold, dtype='int')
    precisions.append(precision_score(y_test, y_predict))
    recalls.append(recall_score(y_test, y_predict))
```


```python
from matplotlib import pyplot as plt
plt.plot(thresholds, precisions)
plt.plot(thresholds, recalls)
plt.show()
```


![image.png](https://upload-images.jianshu.io/upload_images/7220971-93cf7b985a9b6bdf.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)


### Precision-Recall 曲线


```python
plt.plot(precisions, recalls)
```




    [<matplotlib.lines.Line2D at 0x1a132c5b38>]




![image.png](https://upload-images.jianshu.io/upload_images/7220971-cf572538d87530bf.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)


通过曲线再次印证了，精准率和召回率是相互制约的，这个曲线急剧下降的一个点，可能就是精准率和召回率平衡最好的一个位置

### scikit-learn中的Precision-Recall 曲线


```python
from sklearn.metrics import precision_recall_curve

precisions, recalls, thresholds = precision_recall_curve(y_test, decision_scores)
```


```python
# sklearn中会根据我们顶一个的decision_scores的值来取最合适的步长
precisions.shape
```




    (145,)




```python
recalls.shape
```




    (145,)




```python
# The last precision and recall values are 1. and 0. respectively and do not have a corresponding threshold. 
# This ensures that the graph starts on the x axis.
thresholds.shape
```




    (144,)




```python
plt.plot(thresholds, precisions[:-1])
plt.plot(thresholds, recalls[:-1])
# 没有从最小值开始取，在sklearn的封装中，他自动寻找了他认为最重要的数据
plt.show()
```


![image.png](https://upload-images.jianshu.io/upload_images/7220971-f719150d88f62ddf.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)



```python
plt.plot(precisions, recalls)
```




    [<matplotlib.lines.Line2D at 0x1a173457f0>]




![image.png](https://upload-images.jianshu.io/upload_images/7220971-5e41028fc270a992.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)


![image.png](https://upload-images.jianshu.io/upload_images/7220971-3a753a3a683d5233.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

我们用不同的超参数训练不同的模型，每得到一个新的模型，就可以得到一根不同的P-R曲线，如果这个P-R曲线更靠外（也就是与X轴，Y轴所包围的面积越大），那么说明这根曲线对应的模型越好，因为对应这个曲线上的每一个点，他的precision_score和recall_score都比另一个曲线要大
