# 9.5 Precision-Recall的平衡

精准率和召回率这两个指标是互相矛盾的。我们要找到的是这两个指标直接的一个平衡。

### 1.理解为什么二者是矛盾的
回忆我们上一章学习的逻辑回归，通过一系列的推导，我们得出了决策边界:θ<sup>T</sup>·X<sub>b</sub> = 0

![image.png](https://upload-images.jianshu.io/upload_images/7220971-bb2081e7d9a39bd5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

如果我们设置任意一个常量-threshold。可不可以让这个threshold作为决策边界呢
即θ<sup>T</sup>·X<sub>b</sub> = threshold。这样，相当于我们为我们的逻辑回归算法添加了一个新的超参数threshold，通过指定threshold，相对于可以平移决策边界的直线，进而影响逻辑回归的结果。
![image.png](https://upload-images.jianshu.io/upload_images/7220971-4c320737994901a1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

由上图可知，不同的threshold对应的精准率和召回率的关系。随着threshold增大，精准率在不断的变高，而召回率在不断的降低。由此说明精准率和召回率是相互矛盾的


### 2.直观的理解
> 如果想让精准率变高的话，相应的其实就是我们只能讲那些特别有把握的数据分类为1。在这种情况下，实际上我们做的事情是让我们的算法做的事让其判断样本的概率是百分之90甚至百分之99的时候，我们才预测他为1，在这样的情况，很显然有很多真实为1的样本就被排除在了外面，所以召回率就会变低。
如果要让召回率升高，我们就要降低算法判断的概率的threshold，这时却是召回率提高了，但是精准率下降了



### 3.编码观察精准率和召回率的平衡

```python
# 结果即为对于每一个样本来说，在逻辑回归算法中对应的score值是什么
log_reg.decision_function(X_test)[:10]
```




    array([-22.05701166, -33.02939187, -16.21331661, -80.37908046,
           -48.25125463, -24.54003391, -44.39167886, -25.04286766,
            -0.97831023, -19.7173878 ])




```python
# 因为对于前10个样本来说，分数值都是小于0 的，所以预测值都是0
log_reg.predict(X_test)[:10]
```




    array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])




```python
dscision_scores = log_reg.decision_function(X_test)
print(np.min(dscision_scores))
print(np.max(dscision_scores))
```

    -85.68606536672523
    19.889528301315465



```python
# 通过构建新的y_predict，来实现修改threshold为5
y_predict2 = np.array(dscision_scores >= 5, dtype='int')
confusion_matrix(y_test, y_predict2)
```




    array([[404,   1],
           [ 21,  24]])




```python
# 升高threshold后,精准率升高，召回率降低
print(precision_score(y_test, y_predict2))
print(recall_score(y_test, y_predict2))
```

    0.96
    0.5333333333333333
