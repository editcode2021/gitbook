# 5.验证数据集与交叉验证

使用分割训练数据集和测试数据集来判断我们的机器学习性能的好坏，虽然是一个非常好的方案，但是会产生一个问题：针对特定测试数据集过拟合

我们每次使用测试数据来分析性能的好坏。一旦发现结果不好，我们就换一个参数（可能是degree也可能是其他超参数）重新进行训练。这种情况下，我们的模型在一定程度上围绕着测试数据集打转。也就是说我们在寻找一组参数，使得这组参数训练出来的模型在测试结果集上表现的最好。但是由于这组测试数据集是已知的，我们相当于在针对这组测试数据集进行调参，那么他也有可能产生过拟合的情况，**也就是我们得到的模型针对测试数据集过拟合了**
![image.png](https://upload-images.jianshu.io/upload_images/7220971-3e45457bdc59eafb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

那么怎么解决这个问题呢？
解决的方式其实就是：我们需要将我们的问题分为三部分，这三部分分别是训练数据集，验证数据集，测试数据集。
我们使用训练数据集训练好模型之后，将验证数据集送给这个模型，看看这个训练数据集训练的效果是怎么样的，如果效果不好的话，我们重新换参数，重新训练模型。直到我们的模型针对验证数据来说已经达到最优了。
这样我们的模型达到最优以后，再讲测试数据集送给模型，这样才能作为衡量模型最终的性能。换句话说，我们的测试数据集是不参与模型的创建的，而其他两个数据集都参与了训练。但是我们的测试数据集对于模型是完全不可知的，相当于我们在模型这个模型完全不知道的数据

![image.png](https://upload-images.jianshu.io/upload_images/7220971-2f2d1b29d65dcf0b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

这种方法还会有一个问题。由于我们的模型可能会针对验证数据集过拟合，而我们只有一份验证数据集，一旦我们的数据集里有比较极端的情况，那么模型的性能就会下降很多，那么为了解决这个问题，就有了交叉验证。

## 1.交叉验证 Cross Validation
交叉验证相对来说是比较正规的、比较标准的在我们调整我们的模型参数的时候看我们的性能的方式

交叉验证：在训练模型的时候，通常把数据分成k份，例如分成3份（ABC）（分成k分，k属于超参数），这三份分别作为验证数据集和训练数据集。这样组合后可以分别产生三个模型，这三个模型，每个模型在测试数据集上都会产生一个性能的指标，这三个指标的平均值作为当前这个算法训练处的模型衡量的标准是怎样的。
由于我们有一个求平均的过程，所以不会由于一份验证数据集中有比较极端的数据而导致模型有过大的偏差，这比我们只分成训练、验证、测试数据集要更加准确

## 2.编程实现


```python
import numpy as np
from sklearn import datasets
```


```python
digits = datasets.load_digits()
X = digits.data
y = digits.target
```

### 训练train_test_spilt


```python
from sklearn.model_selection import train_test_split

X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.4,random_state =666)
```


```python
from sklearn.neighbors import KNeighborsClassifier

best_score,best_k,best_p = 0,0,0
# k为k近邻中的寻找k个最近元素
for k in range(2,10):
    # p为明科夫斯基距离的p
    for p in range(1,5):
        knn_clf = KNeighborsClassifier(weights='distance',n_neighbors=k,p=p)
        knn_clf.fit(X_train,y_train)
        score = knn_clf.score(X_test,y_test)
        if score > best_score:
            best_score,best_k,best_p = score,k,p
print("Best_score = ",best_score)    
print("Best_k = ",best_k)            
print("Best_p = ",best_p)            
```

    Best_score =  0.9860917941585535
    Best_k =  3
    Best_p =  4


### 使用交叉验证


```python
# 使用sklearn提供的交叉验证
from sklearn.model_selection import cross_val_score

knn_clf = KNeighborsClassifier()
# 返回的是一个数组，有三个元素，说明cross_val_score方法默认将我们的数据集分成了三份
# 这三份数据集进行交叉验证后产生了这三个结果

# cv默认为3，可以修改改参数，修改修改不同分数的数据集
cross_val_score(knn_clf,X_train,y_train,cv=3)
```




    array([0.98895028, 0.97777778, 0.96629213])




```python
# 使用交叉验证的方式来进行调参的过程
best_score,best_k,best_p = 0,0,0
# k为k近邻中的寻找k个最近元素
for k in range(2,10):
    # p为明科夫斯基距离的p
    for p in range(1,5):
        knn_clf = KNeighborsClassifier(weights='distance',n_neighbors=k,p=p)
        scores = cross_val_score(knn_clf,X_train,y_train)
        score = np.mean(scores)
        if score > best_score:
            best_score,best_k,best_p = score,k,p
print("Best_score = ",best_score)    
print("Best_k = ",best_k)            
print("Best_p = ",best_p)            
```

    Best_score =  0.9823599874006478
    Best_k =  2
    Best_p =  2


通过观察两组调参过程的结果可以发现
1.两组调参得出的参数结果是不同的，通常这时候我们更愿意详细使用交叉验证的方式得出的结果。
  因为使用train_test_split很有可能只是过拟合了测试数据集得出的结果
2.使用交叉验证得出的最好分数0.982是小于使用分割训练测试数据集得出的0.986，因为在交叉验证的
  过程中，通常不会过拟合某一组的测试数据，所以平均来讲这个分数会稍微低一些

但是使用交叉验证得到的最好参数Best_score并不是真正的最好的结果，我们使用这种方式只是为了拿到
一组超参数而已，拿到这组超参数后我们就可以训练处我们的最佳模型


```python
knn_clf = KNeighborsClassifier(weights='distance',n_neighbors=2,p=2)
# 用我们找到的k和p。来对X_train,y_train整体fit一下，来看他对X_test,y_test的测试结果
knn_clf.fit(X_train,y_train)
# 注意这个X_test,y_test在交叉验证过程中是完全没有用过的，也就是说我们这样得出的结果是可信的
knn_clf.score(X_test,y_test)
```




    0.980528511821975



### 回顾网格搜素
我们上面的操作，实际上在网格搜索的过程中已经进行了，只不过这个过程是sklean的网格搜索自带的一个过程


```python
# GridSearchCV里的cv实际上就是交叉验证的方式
from sklearn.model_selection import GridSearchCV

param_grid = [
    {
        "weights":['distance'],
        "n_neighbors":[i for i in range(2,10)],
        "p":[i for i in range(1,6)]
    }
]
knn_clf = KNeighborsClassifier()
# cv默认为3，可以修改改参数，修改修改不同分数的数据集
grid_search = GridSearchCV(knn_clf,param_grid,verbose=1,cv=3)
grid_search.fit(X_train,y_train)
```

    Fitting 3 folds for each of 40 candidates, totalling 120 fits


    [Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:  1.0min finished





    GridSearchCV(cv=None, error_score='raise',
           estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
               metric_params=None, n_jobs=1, n_neighbors=5, p=2,
               weights='uniform'),
           fit_params=None, iid=True, n_jobs=1,
           param_grid=[{'weights': ['distance'], 'n_neighbors': [2, 3, 4, 5, 6, 7, 8, 9], 'p': [1, 2, 3, 4, 5]}],
           pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',
           scoring=None, verbose=1)



Fitting 3 folds for each of 40 candidates, totalling 120 fits
 的意思就是交叉验证中分割了三组数据集，而我们的参数组合为8*5=40中组合
3组数据集，30种组合，一共要进行120次的训练


```python
grid_search.best_score_
# 0.9823747680890538 和我们上面得到的best_score 是吻合的
```




    0.9823747680890538




```python
grid_search.best_params_
```




    {'n_neighbors': 2, 'p': 2, 'weights': 'distance'}




```python
best_knn_clf = grid_search.best_estimator_
best_knn_clf.fit(X_train,y_train)
best_knn_clf.score(X_test,y_test)
```




    0.980528511821975


## 3.总结

![image.png](https://upload-images.jianshu.io/upload_images/7220971-81801c65af5a065e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
虽然整体速度慢了，但是这个结果却是可信赖的
极端情况下，K-folds cross validation可以叫做留一法
![image.png](https://upload-images.jianshu.io/upload_images/7220971-2db88d9b22872acd.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)