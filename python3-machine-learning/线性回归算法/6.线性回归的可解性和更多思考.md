## 可解释下
```
lin_reg = LinearRegression()
lin_reg.fit(X,y)
lin_reg.coef_
# 输出：array([-1.05574295e-01,  3.52748549e-02, -4.35179251e-02,  4.55405227e-01,
       -1.24268073e+01,  3.75411229e+00, -2.36116881e-02, -1.21088069e+00,
        2.50740082e-01, -1.37702943e-02, -8.38888137e-01,  7.93577159e-03,
       -3.50952134e-01])
# 将特征结果坐标排序
np.argsort(lin_reg.coef_)
# 输出：array([ 4,  7, 10, 12,  0,  2,  6,  9, 11,  1,  8,  3,  5])

# 将排序过后的坐标对应的名称展示出来，方便观察理解
boston.feature_names[np.argsort(lin_reg.coef_)]
# 输出：array(['NOX', 'DIS', 'PTRATIO', 'LSTAT', 'CRIM', 'INDUS', 'AGE', 'TAX',
       'B', 'ZN', 'RAD', 'CHAS', 'RM'], dtype='<U7')
```

RM对应的是房间数，是正相关最大的特征，也就是说房间数越多，房价越高，这是很合理的
NOX对应的是一氧化氮浓度，也就是说一氧化氮浓度越低，房价越低，这也是非常合理的
由此说明，我们的线性回归具有可解释性，我们可以在对研究一个模型的时候，可以先用线性回归模型看一下，然后根据感性的认识去直观的判断一下是否符合我们的语气

## 6.2 总结
![6.2-1](https://upload-images.jianshu.io/upload_images/7220971-207d239d640630b5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
![6.2-2](https://upload-images.jianshu.io/upload_images/7220971-e3a2b28f8657e2b0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
![6.2-3](https://upload-images.jianshu.io/upload_images/7220971-57f8e00af3e5987f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
![6.2-4](https://upload-images.jianshu.io/upload_images/7220971-3ae395d5fb12edd7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
