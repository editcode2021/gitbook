![1](https://upload-images.jianshu.io/upload_images/7220971-28f661e8edd149d6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

线性回归算法以一个坐标系里一个维度为结果，其他维度为特征（如二维平面坐标系中横轴为特征，纵轴为结果），无数的训练集放在坐标系中，发现他们是围绕着一条执行分布。线性回归算法的期望，就是寻找一条直线，最大程度的“拟合”样本特征和样本输出标记的关系
![2](https://upload-images.jianshu.io/upload_images/7220971-ed83e4dab6237239.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

##### 样本特征只有一个的线性回归问题，为简单线性回归，如房屋价格-房屋面积
将横坐标作为x轴，纵坐标作为y轴，每一个点为（X(i) ,y(i)）,那么我们期望寻找的直线就是y=ax+b，当给出一个新的点x(j)的时候，我们希望预测的y^(j)=ax(j)+b

![7](https://upload-images.jianshu.io/upload_images/7220971-9907accb4deda2e2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
- 不使用直接相减的方式，由于差值有正有负，会抵消
- 不适用绝对值的方式，由于绝对值函数存在不可导的点
![8](https://upload-images.jianshu.io/upload_images/7220971-674c2856a8eb6ccb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

![11](https://upload-images.jianshu.io/upload_images/7220971-a5b3ed8589e06778.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

##### 通过上面的推导，我们可以归纳出一类机器学习算法的基本思路，如下图；其中损失函数是计算期望值和预测值的差值，期望其差值（也就是损失）越来越小，而效用函数则是描述拟合度，期望契合度越来越好
![9](https://upload-images.jianshu.io/upload_images/7220971-4d9f03a1442afd3b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
![10](https://upload-images.jianshu.io/upload_images/7220971-13cf3c2d50fbb1f4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
------------