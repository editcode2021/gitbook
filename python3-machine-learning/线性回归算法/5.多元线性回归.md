# 5.多元线性回归
## 5.1 多元线性回归简介和正规方程解
![5.1-1](https://upload-images.jianshu.io/upload_images/7220971-b47942551895e623.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
![5.1-2](https://upload-images.jianshu.io/upload_images/7220971-99d5435ff88ae007.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
![5.1-3](https://upload-images.jianshu.io/upload_images/7220971-7dd16d69786c892a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
![5.1-4](https://upload-images.jianshu.io/upload_images/7220971-bc789f7481a29101.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

补充（矩阵点乘：A（m行）·B（n列） = A的每一行与B的每一列相乘再相加，等到结果是m行n列的）
![5.1-5](https://upload-images.jianshu.io/upload_images/7220971-1e6d562cb4d08ac3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
补充（一个1xm的行向量乘以一个mx1的列向量等于一个数）
![5.1-6](https://upload-images.jianshu.io/upload_images/7220971-eaded0b058dae228.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
![5.1-7](https://upload-images.jianshu.io/upload_images/7220971-4faa4437792aaa7e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
推导过程参考 https://blog.csdn.net/nomadlx53/article/details/50849941

## 4.2 多元线性回归实现
![4.2-1](https://upload-images.jianshu.io/upload_images/7220971-96238af4246f128b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
```
import numpy as np
from .metrics import r2_score


class LinearRegression:

    def __init__(self):
        """初始化Linear Regression模型"""

        # 系数向量（θ1,θ2,.....θn）
        self.coef_ = None
        # 截距 (θ0)
        self.interception_ = None
        # θ向量
        self._theta = None

    def fit_normal(self, X_train, y_train):
        """根据训练数据集X_train，y_train 训练Linear Regression模型"""
        assert X_train.shape[0] == y_train.shape[0], \
            "the size of X_train must be equal to the size of y_train"

        # np.ones((len(X_train), 1)) 构造一个和X_train 同样行数的，只有一列的全是1的矩阵
        # np.hstack 拼接矩阵
        X_b = np.hstack([np.ones((len(X_train), 1)), X_train])
        # X_b.T 获取矩阵的转置
        # np.linalg.inv() 获取矩阵的逆
        # dot() 矩阵点乘
        self._theta = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y_train)

        self.interception_ = self._theta[0]
        self.coef_ = self._theta[1:]

        return self

    def predict(self, X_predict):
        """给定待预测数据集X_predict，返回表示X_predict的结果向量"""
        assert self.coef_ is not None and self.interception_ is not None,\
            "must fit before predict"
        assert X_predict.shape[1] == len(self.coef_),\
            "the feature number of X_predict must be equal to X_train"

        X_b = np.hstack([np.ones((len(X_predict), 1)), X_predict])
        return X_b.dot(self._theta)

    def score(self, X_test, y_test):
        """根据测试数据集 X_test 和 y_test 确定当前模型的准确度"""

        y_predict = self.predict(X_test)
        return r2_score(y_test, y_predict)

    def __repr__(self):
        return "LinearRegression()"
```

### 预测波士顿房价的测试
```
import numpy as np
import matplotlib.pyplot as plot
from sklearn import datasets

# 加载波士顿房价数据
boston = datasets.load_boston()
X = boston.data
y = boston.target
X = X[y<50.0]
y = y[y<50.0]

# 分割训练集和测试集
from machine_learning.module_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(X,y,seed=666)

# 训练模型
from machine_learning.LinearRegression import LinearRegression
reg = LinearRegression()
reg.fit_normal(X_train,y_train)
# 输出 LinearRegression()

# 结果
reg.coef_
# 输出 array([-1.18919477e-01,  3.63991462e-02, -3.56494193e-02,  5.66737830e-02,
       -1.16195486e+01,  3.42022185e+00, -2.31470282e-02, -1.19509560e+00,
        2.59339091e-01, -1.40112724e-02, -8.36521175e-01,  7.92283639e-03,
       -3.81966137e-01])

reg.interception_
# 输出 34.16143549621706

reg.score(X_test,y_test)
# 输出 0.812980260265849
```
## 4.3 scikit-learn中的回归问题
### scikit-learn 中的线性回归


```python
from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=666)
```


```python
from sklearn.linear_model import LinearRegression

lin_reg = LinearRegression()
```


```python
lin_reg.fit(X_train,y_train)
```




    LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)




```python
lin_reg.coef_
```




    array([-1.14235739e-01,  3.12783163e-02, -4.30926281e-02, -9.16425531e-02,
           -1.09940036e+01,  3.49155727e+00, -1.40778005e-02, -1.06270960e+00,
            2.45307516e-01, -1.23179738e-02, -8.80618320e-01,  8.43243544e-03,
           -3.99667727e-01])




```python
# 由于训练数据集和测试数据集的分割和我们的稍有不同，所以结果会略有不同
lin_reg.intercept_
```




    32.64566083965224




```python
lin_reg.score(X_test,y_test)
```




    0.8008916199519077



### kNN Regressor 实现线性回归


```python
from sklearn.neighbors import KNeighborsRegressor

knn_reg = KNeighborsRegressor()
knn_reg.fit(X_train,y_train)
knn_reg.score(X_test,y_test)
```




    0.602674505080953




```python
# 网格搜索超参数
from sklearn.model_selection import GridSearchCV

param_grid = [
    {
        "weights" : ["uniform"],
        "n_neighbors":[i for i in range(1,11)]
    },
    {
        "weights" : ["distance"],
        "n_neighbors":[i for i in range(1,11)],
        "p":[i for i in range(1,6)]
    }
]

knn_reg = KNeighborsRegressor()
grid_search = GridSearchCV(knn_reg,param_grid,n_jobs=-1,verbose=1)
grid_search.fit(X_train,y_train)
```

    Fitting 3 folds for each of 60 candidates, totalling 180 fits


    [Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:    0.5s finished





    GridSearchCV(cv=None, error_score='raise',
           estimator=KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
              metric_params=None, n_jobs=1, n_neighbors=5, p=2,
              weights='uniform'),
           fit_params=None, iid=True, n_jobs=-1,
           param_grid=[{'weights': ['uniform'], 'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}, {'weights': ['distance'], 'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'p': [1, 2, 3, 4, 5]}],
           pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',
           scoring=None, verbose=1)




```python
grid_search.best_params_
```




    {'n_neighbors': 6, 'p': 1, 'weights': 'distance'}




```python
# 运用了CV交叉验证的方式
grid_search.best_score_
```




    0.6060327991735741




```python
grid_search.best_estimator_.score(X_test,y_test)
```




    0.7354244906092771
