# 1. 梯度下降法简介
![1-1](https://upload-images.jianshu.io/upload_images/7220971-b5cbb15c453a8bff.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
以下是定义了一个损失函数以后，参数theta对应的损失函数J的值对应的示例图，我们需要找到使得损失函数值J取得最小值对应的theta（这里是二维平面，也就是我们的参数只有一个）

在直线方程中，导数代表斜率
在曲线方程中，导数代表切线斜率
导数代表theta单位变化时，J相应的变化
![1-2](https://upload-images.jianshu.io/upload_images/7220971-ff7b7ee6b96eda21.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
![1-3](https://upload-images.jianshu.io/upload_images/7220971-036be3c10d1717ff.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
η太小，会减慢收敛学习速度
![1-4](https://upload-images.jianshu.io/upload_images/7220971-c7c85bf76d842bdf.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
η太大，甚至导致不收敛
![1-5](https://upload-images.jianshu.io/upload_images/7220971-97b6433c576625be.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

## 其他注意事项
- 并不是所有函数都有唯一的极值点
![1-6](https://upload-images.jianshu.io/upload_images/7220971-4132d86840e35ce2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
  解决方案：
    - 多次运行，随机化初始点
    - 梯度下降法的初始点也是一个超参数

![1-7](https://upload-images.jianshu.io/upload_images/7220971-91e48d44174b6f34.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
