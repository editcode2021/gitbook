# 3.主成分PCA的实现



### 使用梯度上升法求解主成分


```python
import numpy as np
import matplotlib.pyplot as plt
```

- #### 构造一个两个样本之间有基本线性关系的数据集，可以使得我们降维的效果更加明显


```python
X = np.empty((100,2))
X[:,0] = np.random.uniform(0.,100.,size=100)
# 0.75倍的X[:,0]加上3加上一个噪音
X[:,1] = 0.75*X[:,0]+3.+np.random.normal(0.,10.,size=100)
```


```python
plt.scatter(X[:,0],X[:,1])
```




    <matplotlib.collections.PathCollection at 0x111f2e4e0>




![3-1](https://upload-images.jianshu.io/upload_images/7220971-d5fc0d2da26ca2b4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)


- #### 均值归0


```python
def demean(X):
    return X-np.mean(X,axis=0)
```


```python
X_demean = deamean(X)
plt.scatter(X_demean[:,0],X_demean[:,1])
```




    <matplotlib.collections.PathCollection at 0x111d8e438>




![3-2](https://upload-images.jianshu.io/upload_images/7220971-6f4ee13902854b90.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)



### 梯度上升法


```python
def f(w,X):
    return np.sum((X.dot(w)**2))/len(X)
```


```python
def df_math(w,X):
    return X.T.dot(X.dot(w)) * 2. /len(X)
```


```python
def df_debug(w,X,epsilon=0.0001):
    res = np.empty(len(w))
    for i in range(len(w)):
        w_1 = w.copy()
        w_1[i] += epsilon
        w_2 = w.copy()
        w_2[i] -= epsilon
        res[i] = (f(w_1,X)-f(w_2,X)) / (2*epsilon)
    return res
```


```python
def direction(w):
    """计算单位向量"""
    return w / np.linalg.norm(w)

def gradient_ascent(df,X,inital_w,eta,n_iters = 1e4,epsilon=1e-8):
    
    w = direction(inital_w)
    cur_iter = 0
    
    while cur_iter < n_iters:
        gradient = df(w,X)
        last_w = w
        w = w + eta * gradient
        # 注意1：每次求单位向量
        w = direction(w) 
        if abs(f(w,X)-f(last_w,X)) < epsilon:
            break
            
        cur_iter = cur_iter+1
    return w
```


```python
# 初始值不能为0，因为将0带入求导公式，会发现得0，没有任何方向
# 因为对于我们的目标函数来说，w=0本身就是一个最小值点

## 注意2：不能从0向量开始
inital_w = np.random.random(X.shape[1])
eta = 0.01
```


```python
# 注意3：不能使用StandardScaler标准化数据
# 因为我们本来就是要使得方差最大，而标准化的目的是使得方差为1
```


```python
# 使用debug模式
gradient_ascent(df_debug,X_demean,inital_w,eta)
# 输出  array([0.75934073, 0.65069321])

# 使用math数学解
gradient_ascent(df_math,X_demean,inital_w,eta)
# 输出     array([0.75934073, 0.65069321])
```

```python
w = gradient_ascent(df_math,X_demean,inital_w,eta)
plt.scatter(X_demean[:,0],X_demean[:,1])
# 这个轴就是我们求出的第一个主成分
plt.plot([0,w[0]*30],[0,w[1]*30],color='r')
```

![3-3](https://upload-images.jianshu.io/upload_images/7220971-8870bf84f0b4a7a4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

-----------------